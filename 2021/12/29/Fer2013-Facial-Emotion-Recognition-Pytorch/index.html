<!DOCTYPE html>
<html lang="">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Lethe">


    <meta name="subtitle" content="Life is a struggle">


    <meta name="description" content="Lethe's Blog">


    <meta name="keywords" content="Lethe's Blog">


<title>Fer2013-Facial-Emotion-Recognition-Pytorch | Lethe&#39;s Blog</title>



    <link rel="icon" href="https://s2.ax1x.com/2019/10/30/K5JenU.png">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 6.1.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Lethe&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Lethe&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Fer2013-Facial-Emotion-Recognition-Pytorch</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Lethe</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">December 29, 2021&nbsp;&nbsp;20:49:11</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/AI/">AI</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>【这学期计算机视觉课程的结课作业中可选的最简单的一个题目，最终虽然没啥新东西，但是意外的性能好像还可以】</p>
<p>本次实验达到了Fer2013原始数据集单模型(不使用额外训练数据)的SOTA准确率 73.70%，代码已上传至GitHub：<a target="_blank" rel="noopener" href="https://github.com/LetheSec/Fer2013-Recognition-Pytorch">https://github.com/LetheSec/Fer2013-Recognition-Pytorch</a></p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><p>表情识别是计算机理解人类情感的一个重要方向，也是人机交互的一个重要方面。表情识别是指从静态照片或视频序列中选择出表情状态，从而确定对人物的情绪与心理变化。20世纪70年代的美国心理学家Ekman和Friesen通过大量实验，定义了人类六种基本表情：快乐，气愤，惊讶，害怕，厌恶和悲伤，除此之外后续的分类任务大多增添了一个中性表情。人脸表情识别（FER）在人机交互和情感计算中有着广泛的研究前景，包括人机交互、情绪分析、智能安全等。</p>
<p>本次实验的使用的数据集为Fer2013，它于2013年国际机器学习会议（ICML）上推出，并成为比较表情识别模型性能的基准之一，同时也作为了2013年Kaggle人脸识别比赛的数据。Fer2013包含28709张训练集图像、3589张公开测试集图像和3589张私有测试集图像，每张图像为4848大小的灰度图片，如下图所示。Fer2013数据集中由有生气(angry)、厌恶(disgust)、恐惧(fear)、开心(happy)、难过(sad)、惊讶(surprise)和中性(neutral)七个类别组成。由于这个数据集大多是通过爬虫在互联网上进行爬取所得，因此存在一定的误差性，人类在该数据集上的准确率为 。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-4bc79d02c86eb8e5e5ba36fba2fb4bc3_b.jpg" alt="img"></p>
<p>而在本次的实验提供的数据集是经过重新划分的，其中训练集只有17591张图像，比原始数据集少了近40%，而验证集和测试集数量则大幅增加，因此理论上在课程数据集上的性能会低于在原始数据集上的性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-b1d7aa6a1e688709e157744bf2fb3ba5_b.jpg" alt="img"></p>
<p>除此之外，该数据集七个类别样本数量并不是想等的，其中disgust类别的数量最少，happy类别样本数量最多。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-8e000bdbf864d23f255212803baacd13_b.jpg" alt="img"></p>
<h1 id="2-基准"><a href="#2-基准" class="headerlink" title="2 基准"></a>2 基准</h1><p>为了后续实验有一个评价的基准，首先需要寻找目前Fer2013表情识别认为的Baseline方法。Papers With Code网站[1]收集了AI领域各个方向的论文对应代码，并形成了许多的benchmark排行榜用于研究者进行比较，并及时跟进最新的进展情况，该网站的Fer2013数据集排行榜如下图所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-71e7dacac873b5f3e9b8e5db90e41239_b.jpg" alt="img"></p>
<p>其中，前三名在Fer2013数据集之外还使用了额外的数据参与训练，与本次实验的目标不符，因此第四名[2]VGGNet所达到的73.28%即为单模型在Fer2013数据集上不使用额外训练数据时的表分类SOTA，我将该方法作为本次试验的Baseline。该方法基于VGG提出了一个变种的网络，并通过尝试不同的数据增强策略、学习率策略、优化器的选择，以及大量的参数调整，最终达到了单模型的SOTA性能。</p>
<p>我首先对该Baseline进行复现，作者在GitHub上开源了论文代码[3]，我使用原始代码及默认超参数进行复现，结果如下表所示(reproduce表示复现的结果，report表示论文给出的结果)。可以看到，使用Fer2013原始训练集进行训练，可以在其私有测试集上达到72.22%的准确率，比论文中汇报的73.28%要低，只能通过作者提供的预训练权重来达到该准确率。而使用Baseline代码在课程数据集上的训练集上训练，可以在课程验证集上达到70.09%的准确率。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-27d938a62b780daa3be0efb66fb88a3c_b.jpg" alt="img"></p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-5b6f195199a9e2fcdd7beae96618da6c_b.jpg" alt="img" style="zoom: 67%;">

<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-a59a84a932149314570da9185312aaac_b-20220328134055779.jpg" alt="img" style="zoom: 67%;">

<h1 id="3-方法及实验"><a href="#3-方法及实验" class="headerlink" title="3 方法及实验"></a>3 方法及实验</h1><p>首先，根据之前的经验实现一个最基本的分类网络，使用ResNet18作为主干网络，epoch设置为300，batch size为128，损失函数为交叉熵损失，优化器选择SGD，并设置学习率为0.1，momentum为0.9，weight decay为1e-4，并使用了余弦退火学习率衰减策略。</p>
<h2 id="3-1-数据增强"><a href="#3-1-数据增强" class="headerlink" title="3.1 数据增强"></a>3.1 数据增强</h2><p>首先，我对数据增强的策略进行探索，对于这种训练集样本数量不够的情况，合适的数据增强策略通常能够很好的提高模型的泛化能力。除此之外，由于Fer2013数据集是通过爬虫进行爬取的数据，因此数据集的差异较大，数据增强也能很好的提高性能。经过尝试与比较，最终使用了如下几种数据增强策略：</p>
<ul>
<li>RandomHorizontalFlip：随机水平翻转</li>
<li>RandomResizedCrop：随机裁剪</li>
<li>RandomRotation：随机旋转</li>
<li>ColorJitter：随机颜色抖动</li>
<li>RandomAffine：随机仿射变换</li>
<li>RandomErasing：随机图像擦除</li>
</ul>
<p>并且我通过消融实验，证明了每一种数据增强的策略都确实是能够对性能有所提升，实验结果如下。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-ae433464c45ee4bd595a77943ad820bb_b.jpg" alt="img"></p>
<p>在上表中，当只使用基本的分类网络，不使用任何数据增强策略时，在验证集上只达到了57.45%的准确率。但是，随着数据增强策略的逐渐累加，准确率也有所 提升，其中使用随机剪裁时准确率提升了5.08%左右。最终，在基本分类网络上使用这六种数据增强策略，能达到69.19%的验证集准确率。在下图中，上图为一组原始训练样本，下图为使用六种随机数据增强策略后的训练样本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-84d2f40df4aed0cd06fa62194d22f17e_b.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-b98696d9bbc518b67ac979107c4f3d82_b.jpg" alt="img"></p>
<h2 id="3-2-学习率策略"><a href="#3-2-学习率策略" class="headerlink" title="3.2 学习率策略"></a>3.2 学习率策略</h2><p>在基本的分类网络中，我凭借之前的做其他分类任务的经验，选择了使用余弦退火学习率衰减策略(CosineAnnealingLR)，该策略时让学习率随训练epoch的变化图像类似于余弦函数图像，并结合数据增强策略最终得到了69.19%的准确率。而我注意到baseline方法中使用的学习率策略为ReduceLROnPlateau，该策略可以提前指定某一个性能评价指标（如验证集准确率），当训练过程中该指标不再增大(或减小)，则适当的降低学习率。因此，我对两种学习率衰减策略进行了比较，实验结果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-2f0c2679fb9c9c35f7edc0d854afbbfc_b.jpg" alt="img"></p>
<p>通过对比可以发现，在结合不同的数据增强策略时，使用余弦退火学习率衰减策略比baseline中使用ReduceLROnPlateau策略总能具有更好的性能。</p>
<h2 id="3-3-Label-Smooth与Mixup"><a href="#3-3-Label-Smooth与Mixup" class="headerlink" title="3.3 Label Smooth与Mixup"></a>3.3 Label Smooth与Mixup</h2><p>Label Smooth（标签平滑）是一种正则化的思想，通过对标签的one-hot分布加入一定的噪音分布，从而起到“软化”的效果，防止模型对预测结果过于自信，从而导致过拟合。</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-977dd17b7b00a7976df7e4f5ac341f4b_b.jpg" alt="img" style="zoom: 50%;">

<p>由于Fer2013数据集中存在不少非预期样本（如下图所示），这些样本是不属于任一类别的离群点，因此如果模型过拟合这些样本的话，则会降低泛化能力，从而降低性能。</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-fdf3e67b1eaa80461f555db10a5cbf43_b.jpg" alt="img" style="zoom:75%;">

<p>Mixup则是一种数据增强的思想，它将两张图片按照一定的比例进行融合，同时对它们的one-hot标签也进行同比例的融合：</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-fa69324b85082436911eca0c7860aa95_b.jpg" alt="img" style="zoom:50%;">

<p>Mixup的效果如下图所示，通过这样的做法，可以让模型在对一张融合后的样本判断出混合前的两个类别，从而能够提高训练的效果。</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-5fca6ea6926580162f04e826a3b74c48_b.jpg" alt="img" style="zoom:75%;">

<p>我在当前最优的策略上，使用Label Smooth和Mixup策略进行实验，结果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-bc2547c8d16b42c2bcb1cbda16f1a633_b.jpg" alt="img"></p>
<p>可以看出，在使用数据增强与学习率衰减策略后，单独使用Label Smooth和Mixup都能进一步提高模型在验证集上的准确率。而如果同时使用Label Smooth和Mixup时，在验证集上的准确率均超过了70%，已经与baseline在课程数据集上的性能大致相当。</p>
<p>除此之外，通过下图验证集在训练时的Loss曲线可以看出，当不使用Label Smooth和Mixup策略时（橙色曲线），模型随着训练epoch的增加很容易出现过拟合的现象。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-6e9776a1128689e28664b588f14f8d28_b.jpg" alt="img"></p>
<h2 id="3-4-N-Crop"><a href="#3-4-N-Crop" class="headerlink" title="3.4 N-Crop"></a>3.4 N-Crop</h2><p>在3.3节中，已经能在课程验证集上达到与baseline方法相当的性能，于是继续尝试使用N-Crop策略，其分为FiveCrop和TenCrop：</p>
<p>（1）FiveCrop: 在图像的左上角、右上角、左下角、右下角和图像中间分别裁剪一个指定大小的子图像，从而将可以将样本数量扩充至原来的<strong>五倍</strong></p>
<p>（2）TenCrop: 在FiveCrop的基础上，再将每张子图像进行水平翻转，从而将样本数量扩充至原来的<strong>十倍</strong>。</p>
<p>这样，当在模型训练的时候使用N-Crop策略，则可以大幅增加训练集的数量，但同时也需要更长的训练时间以及更大的显存；而如果在模型推理时使用N-Crop，则是对多种子图的预测概率去取平均，从而降低模型的错误率。因此，我将N-Crop策略与之前的策略结合，实验结果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-077fa3d300051ace9cb5416d1cf2ad00_b.jpg" alt="img"></p>
<p>从上表中可以看出，将N-Crop与之前的策略相结合，能够带来性能的提升；并且当在推理的时候使用TenCrop，所有情况下的表现均会更优。最终，在3.4节最优策略的基础上，在模型训练时使用FiveCrop，在模型推理时使用TenCrop，并且使用余弦退火学习率衰减策略时，达到了最优的性能，可以在验证集上达到71.37%的准确率，与Baseline方法在课程验证集上的准确率相比，提升了1.28%。</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-91620e3f89c1307261aca313f773df0e_b.jpg" alt="img" style="zoom: 67%;">

<h2 id="3-5-模型集成"><a href="#3-5-模型集成" class="headerlink" title="3.5 模型集成"></a>3.5 模型集成</h2><p>至此，本次实验已经可以在ResNet18单模型上达到71.37%的验证集准确率，超过了Baseline方法，下面考虑使用集成模型进一步提高准确率。首先，我使用当前最优策略在不同的主干网络上进行实验，得到如下结果：</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-f33108b74140215f5e2404c274776042_b.jpg" alt="img" style="zoom: 50%;">

<p>可以看出，最开始选用的ResNet18仍然时性能最好的主干网络，DenseNet、DLA、ResNet34等略低于它。由于时间及显存的限制，我这里仅考虑前四个模型进行集成，并且没有选择投票的集成方式，而是使用了logits融合，结果如下：</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-a156587429eb563c645d8920230f3fd8_b.jpg" alt="img" style="zoom:50%;">

<p>其中，第2行和第4行的集成模型，直接使用logits平均进行集成，性能相较于单模型有所提升。最后一行，则对四个模型的logtis权重进行了一定的调整，最终集成模型可以在验证集上达到72.14%的准确率。另外，本次实验重点放在了单模型的性能提升，对于集成模型的提升并没有做过多的探究。</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-25f881198d7aacd80543dacb6431615a_b.jpg" alt="img" style="zoom:67%;">

<h2 id="3-6-其他"><a href="#3-6-其他" class="headerlink" title="3.6 其他"></a>3.6 其他</h2><p>除了上述策略之外，我在实验过程也进行了一些其他的尝试：</p>
<ol>
<li>在ResNet18全连接层前加Dropout，效果没有提升的原因可能是Dropout与ResNet中的BN层有一定的冲突[4]。</li>
</ol>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-b681f0e966cc313c0b1a8a7a83982fe7_b.jpg" alt="img" style="zoom: 67%;">

<ol>
<li>使用带权重的交叉熵损失<strong>：</strong>用样本数量的倒数作为权重，效果没有提升，可能是因为样本差异实在太大，直接这样子设置权重会损害对样本数量多的类别的学习，也许通过进一步优化权重，可以有所提升。</li>
<li>所有试验均固定了随机种子，保证结果可复现性。</li>
<li>使用自动混合精度(AMP)训练，从而提高训练速度。</li>
</ol>
<h1 id="4-原始数据集评估"><a href="#4-原始数据集评估" class="headerlink" title="4 原始数据集评估"></a>4 原始数据集评估</h1><p>在第三节中，我通过多种策略的组合与实验，最终在课程数据集的验证集上达到了**单模型71.37%<strong>、</strong>集成模型72.14%**的准确率，均超过了Baseline。但是由于Baseline的复现结果并不理想，为了更加公平的将本方法与其进行对比。</p>
<p>下面将使用了Fer2013原始数据集对本实验的最优方法进行评估，即在原始训练集上进行训练，以私有测试集的准确率作为评价标准。实验结果如下：</p>
<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-4594474eb4e656b80053574e6796f4d3_b.jpg" alt="img" style="zoom:67%;">

<img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-2e8acca10e3882c175cef041a5aac6c5_b.jpg" alt="img" style="zoom:67%;">

<p>最终，本实验的最优方法在Fer2013原始数据集的私有测试集上达到了<strong>73.70%<strong>的准确率，超过Baseline方法论文[2]中汇报的73.28%的准确率，</strong>达到了目前Fer2013数据集单模型表情识别(不使用额外训练数据)SOTA</strong>。并且注意到，我使用的仍是课程数据集下所设置的参数，并没有在原始数据集上进行重新调参，因此可能还有进一步提升的空间。</p>
<p>（手动上榜hhh）</p>
<p><img src="https://cdn.jsdelivr.net/gh/LetheSec/oss@master/Blog/Fer2013-Facial-Emotion-Recognition-Pytorch/v2-6a8a5cc16d15f614e2b1affb917e31fa_b.jpg" alt="img"></p>
<p>在Fer2013原始数据集上的实验代码及权重已上传至本人GitHub：<a href="https://link.zhihu.com/?target=https://github.com/LetheSec/Fer2013-Recognition-Pytorch">https://github.com/LetheSec/Fer2013-Recognition-Pytorch</a></p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>（1）本次实验，最终在课程数据集的验证集上使用单模型达到了71.37%的准确率，使用集成模型达到了72.14%的准确率；在原始数据集的私有测试集上单模型达到了73.70%的准确率。</p>
<p>（2）其中73.70%成为Fer2013数据集(不使用额外训练数据)单模型表情识别的新SOTA。</p>
<p>（3）实验没有去耗费大量时间进行调参，大多参数直接进行直觉的选择。</p>
<p>（4）本次实验的重点在单模型的性能提升，并没有过多关注与类别不均衡问题与模型集成的技巧，这也是未来可以进一步改进的地方。</p>
<h1 id="6-参考"><a href="#6-参考" class="headerlink" title="6 参考"></a>6 参考</h1><p>[1] <a href="https://link.zhihu.com/?target=https://paperswithcode.com/sota/facial-expression-recognition-on-fer2013">https://paperswithcode.com/sota/facial-expression-recognition-on-fer2013</a></p>
<p>[2] Khaireddin, Yousif, and Zhuofa Chen. “Facial Emotion Recognition: State of the Art Performance on FER2013.” arXiv preprint arXiv:2105.03588 (2021).</p>
<p>[3] <a href="https://link.zhihu.com/?target=https://github.com/usef-kh/fer">https://github.com/usef-kh/fer</a></p>
<p>[4] Li, Xiang, et al. “Understanding the disharmony between dropout and batch normalization by variance shift.” Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition. 2019.</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Lethe</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://lethe.site/2021/12/29/Fer2013-Facial-Emotion-Recognition-Pytorch/">https://lethe.site/2021/12/29/Fer2013-Facial-Emotion-Recognition-Pytorch/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2022 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/AI/"># AI</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/03/20/algorithm_course/">USTC-算法分析与设计</a>
            
            
            <a class="next" rel="next" href="/2020/12/25/NCE-and-InfoNCE/">Noise Contrastive Estimation 前世今生——从 NCE 到 InfoNCE</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>Life is a struggle.</span>
        <!-- <span>© Lethe | 2019 - 2022</span> -->
    </div>
</footer>

    </div>
</body>

</html>